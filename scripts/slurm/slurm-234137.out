Your working directories are::
LOAD::>  /jmain02/home/J2AD009/ttl04/aat50-ttl04/road-dataset/ 
SAVE::>  /jmain02/home/J2AD009/ttl04/aat50-ttl04/road-dataset/
Your model will be initialized using /jmain02/home/J2AD009/ttl04/aat50-ttl04/3D-RetinaNet/kinetics-pt/resnet50I3D.pth
[INFO: main.py:  196]: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) 
[GCC 9.4.0]
[INFO: datasets.py:  370]: Number of agent: all :: 11 to use: 10
[INFO: datasets.py:  370]: Number of action: all :: 22 to use: 19
[INFO: datasets.py:  370]: Number of loc: all :: 12 to use: 12
[INFO: datasets.py:  370]: Number of duplex: all :: 152 to use: 39
[INFO: datasets.py:  370]: Number of triplet: all :: 1620 to use: 68
[INFO: datasets.py:  452]: Frames with Boxes are 4033 out of 4734 in 2014-06-25-16-45-34_stereo_centre_02
[INFO: datasets.py:  459]: number of start frames: 591
[INFO: datasets.py:  452]: Frames with Boxes are 5597 out of 6001 in 2014-07-14-14-49-50_stereo_centre_01
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 5345 out of 6000 in 2014-07-14-15-42-55_stereo_centre_03
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 5801 out of 6001 in 2014-08-08-13-15-11_stereo_centre_01
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 1168 out of 1168 in 2014-08-11-10-59-18_stereo_centre_02
[INFO: datasets.py:  459]: number of start frames: 146
[INFO: datasets.py:  452]: Frames with Boxes are 5134 out of 6000 in 2014-11-14-16-34-33_stereo_centre_06
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 5724 out of 6000 in 2014-11-18-13-20-12_stereo_centre_05
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 4804 out of 6001 in 2014-11-21-16-07-03_stereo_centre_01
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 5710 out of 6001 in 2014-12-09-13-21-02_stereo_centre_01
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 5611 out of 6000 in 2015-02-03-08-45-10_stereo_centre_02
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 5473 out of 6000 in 2015-02-03-19-43-11_stereo_centre_04
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 5431 out of 6000 in 2015-02-06-13-57-16_stereo_centre_02
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 5316 out of 6000 in 2015-02-13-09-16-26_stereo_centre_05
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 5859 out of 6000 in 2015-02-24-12-32-19_stereo_centre_04
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: datasets.py:  452]: Frames with Boxes are 5133 out of 6001 in 2015-03-03-11-31-36_stereo_centre_01
[INFO: datasets.py:  459]: number of start frames: 750
[INFO: main.py:  222]: Done Loading Dataset Train Dataset
[INFO: datasets.py:  370]: Number of agent: all :: 11 to use: 10
[INFO: datasets.py:  370]: Number of action: all :: 22 to use: 19
[INFO: datasets.py:  370]: Number of loc: all :: 12 to use: 12
[INFO: datasets.py:  370]: Number of duplex: all :: 152 to use: 39
[INFO: datasets.py:  370]: Number of triplet: all :: 1620 to use: 68
[INFO: datasets.py:  452]: Frames with Boxes are 5307 out of 6000 in 2014-06-26-09-53-12_stereo_centre_02
[INFO: datasets.py:  459]: number of start frames: 94
[INFO: datasets.py:  452]: Frames with Boxes are 5844 out of 6000 in 2014-11-25-09-18-32_stereo_centre_04
[INFO: datasets.py:  459]: number of start frames: 94
[INFO: datasets.py:  452]: Frames with Boxes are 5091 out of 6000 in 2015-02-13-09-16-26_stereo_centre_02
[INFO: datasets.py:  459]: number of start frames: 94
[INFO: main.py:  250]: Done Loading Dataset Validation Dataset
[INFO: main.py:  275]: Using the plain model with empty CCN layer
[INFO: resnetFPN.py:  275]: **LOAD STAE DICTIONARY FOR WEIGHT INITLISATIONS**
[INFO: resnetFPN.py:  317]: conv1.weighttorch.Size([64, 3, 1, 7, 7]) ==>>torch.Size([64, 3, 1, 7, 7])
[INFO: resnetFPN.py:  317]: bn1.weighttorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: bn1.biastorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: bn1.running_meantorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: bn1.running_vartorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer1.0.conv1.weighttorch.Size([64, 64, 3, 1, 1]) ==>>torch.Size([64, 64, 3, 1, 1])
[INFO: resnetFPN.py:  317]: layer1.0.bn1.weighttorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.0.bn1.biastorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.0.bn1.running_meantorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.0.bn1.running_vartorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.0.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer1.0.conv2.weighttorch.Size([64, 64, 1, 3, 3]) ==>>torch.Size([64, 64, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer1.0.bn2.weighttorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.0.bn2.biastorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.0.bn2.running_meantorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.0.bn2.running_vartorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.0.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer1.0.conv3.weighttorch.Size([256, 64, 1, 1, 1]) ==>>torch.Size([256, 64, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer1.0.bn3.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.0.bn3.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.0.bn3.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.0.bn3.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.0.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer1.0.downsample.0.weighttorch.Size([256, 64, 1, 1, 1]) ==>>torch.Size([256, 64, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer1.0.downsample.1.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.0.downsample.1.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.0.downsample.1.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.0.downsample.1.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.0.downsample.1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer1.1.conv1.weighttorch.Size([64, 256, 3, 1, 1]) ==>>torch.Size([64, 256, 3, 1, 1])
[INFO: resnetFPN.py:  317]: layer1.1.bn1.weighttorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.1.bn1.biastorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.1.bn1.running_meantorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.1.bn1.running_vartorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.1.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer1.1.conv2.weighttorch.Size([64, 64, 1, 3, 3]) ==>>torch.Size([64, 64, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer1.1.bn2.weighttorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.1.bn2.biastorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.1.bn2.running_meantorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.1.bn2.running_vartorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.1.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer1.1.conv3.weighttorch.Size([256, 64, 1, 1, 1]) ==>>torch.Size([256, 64, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer1.1.bn3.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.1.bn3.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.1.bn3.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.1.bn3.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.1.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer1.2.conv1.weighttorch.Size([64, 256, 3, 1, 1]) ==>>torch.Size([64, 256, 3, 1, 1])
[INFO: resnetFPN.py:  317]: layer1.2.bn1.weighttorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.2.bn1.biastorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.2.bn1.running_meantorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.2.bn1.running_vartorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.2.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer1.2.conv2.weighttorch.Size([64, 64, 1, 3, 3]) ==>>torch.Size([64, 64, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer1.2.bn2.weighttorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.2.bn2.biastorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.2.bn2.running_meantorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.2.bn2.running_vartorch.Size([64]) ==>>torch.Size([64])
[INFO: resnetFPN.py:  317]: layer1.2.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer1.2.conv3.weighttorch.Size([256, 64, 1, 1, 1]) ==>>torch.Size([256, 64, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer1.2.bn3.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.2.bn3.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.2.bn3.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.2.bn3.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer1.2.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.0.conv1.weighttorch.Size([128, 256, 3, 1, 1]) ==>>torch.Size([128, 256, 3, 1, 1])
[INFO: resnetFPN.py:  317]: layer2.0.bn1.weighttorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.0.bn1.biastorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.0.bn1.running_meantorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.0.bn1.running_vartorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.0.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.0.conv2.weighttorch.Size([128, 128, 1, 3, 3]) ==>>torch.Size([128, 128, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer2.0.bn2.weighttorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.0.bn2.biastorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.0.bn2.running_meantorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.0.bn2.running_vartorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.0.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.0.conv3.weighttorch.Size([512, 128, 1, 1, 1]) ==>>torch.Size([512, 128, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer2.0.bn3.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.0.bn3.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.0.bn3.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.0.bn3.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.0.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.0.downsample.0.weighttorch.Size([512, 256, 1, 1, 1]) ==>>torch.Size([512, 256, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer2.0.downsample.1.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.0.downsample.1.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.0.downsample.1.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.0.downsample.1.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.0.downsample.1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.1.conv1.weighttorch.Size([128, 512, 1, 1, 1]) ==>>torch.Size([128, 512, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer2.1.bn1.weighttorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.1.bn1.biastorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.1.bn1.running_meantorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.1.bn1.running_vartorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.1.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.1.conv2.weighttorch.Size([128, 128, 1, 3, 3]) ==>>torch.Size([128, 128, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer2.1.bn2.weighttorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.1.bn2.biastorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.1.bn2.running_meantorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.1.bn2.running_vartorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.1.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.1.conv3.weighttorch.Size([512, 128, 1, 1, 1]) ==>>torch.Size([512, 128, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer2.1.bn3.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.1.bn3.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.1.bn3.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.1.bn3.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.1.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.2.conv1.weighttorch.Size([128, 512, 3, 1, 1]) ==>>torch.Size([128, 512, 3, 1, 1])
[INFO: resnetFPN.py:  317]: layer2.2.bn1.weighttorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.2.bn1.biastorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.2.bn1.running_meantorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.2.bn1.running_vartorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.2.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.2.conv2.weighttorch.Size([128, 128, 1, 3, 3]) ==>>torch.Size([128, 128, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer2.2.bn2.weighttorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.2.bn2.biastorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.2.bn2.running_meantorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.2.bn2.running_vartorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.2.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.2.conv3.weighttorch.Size([512, 128, 1, 1, 1]) ==>>torch.Size([512, 128, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer2.2.bn3.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.2.bn3.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.2.bn3.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.2.bn3.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.2.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.3.conv1.weighttorch.Size([128, 512, 1, 1, 1]) ==>>torch.Size([128, 512, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer2.3.bn1.weighttorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.3.bn1.biastorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.3.bn1.running_meantorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.3.bn1.running_vartorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.3.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.3.conv2.weighttorch.Size([128, 128, 1, 3, 3]) ==>>torch.Size([128, 128, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer2.3.bn2.weighttorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.3.bn2.biastorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.3.bn2.running_meantorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.3.bn2.running_vartorch.Size([128]) ==>>torch.Size([128])
[INFO: resnetFPN.py:  317]: layer2.3.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer2.3.conv3.weighttorch.Size([512, 128, 1, 1, 1]) ==>>torch.Size([512, 128, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer2.3.bn3.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.3.bn3.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.3.bn3.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.3.bn3.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer2.3.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.0.conv1.weighttorch.Size([256, 512, 3, 1, 1]) ==>>torch.Size([256, 512, 3, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.0.bn1.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.0.bn1.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.0.bn1.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.0.bn1.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.0.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.0.conv2.weighttorch.Size([256, 256, 1, 3, 3]) ==>>torch.Size([256, 256, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer3.0.bn2.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.0.bn2.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.0.bn2.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.0.bn2.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.0.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.0.conv3.weighttorch.Size([1024, 256, 1, 1, 1]) ==>>torch.Size([1024, 256, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.0.bn3.weighttorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.0.bn3.biastorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.0.bn3.running_meantorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.0.bn3.running_vartorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.0.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.0.downsample.0.weighttorch.Size([1024, 512, 1, 1, 1]) ==>>torch.Size([1024, 512, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.0.downsample.1.weighttorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.0.downsample.1.biastorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.0.downsample.1.running_meantorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.0.downsample.1.running_vartorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.0.downsample.1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.1.conv1.weighttorch.Size([256, 1024, 1, 1, 1]) ==>>torch.Size([256, 1024, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.1.bn1.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.1.bn1.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.1.bn1.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.1.bn1.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.1.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.1.conv2.weighttorch.Size([256, 256, 1, 3, 3]) ==>>torch.Size([256, 256, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer3.1.bn2.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.1.bn2.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.1.bn2.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.1.bn2.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.1.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.1.conv3.weighttorch.Size([1024, 256, 1, 1, 1]) ==>>torch.Size([1024, 256, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.1.bn3.weighttorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.1.bn3.biastorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.1.bn3.running_meantorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.1.bn3.running_vartorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.1.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.2.conv1.weighttorch.Size([256, 1024, 3, 1, 1]) ==>>torch.Size([256, 1024, 3, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.2.bn1.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.2.bn1.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.2.bn1.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.2.bn1.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.2.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.2.conv2.weighttorch.Size([256, 256, 1, 3, 3]) ==>>torch.Size([256, 256, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer3.2.bn2.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.2.bn2.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.2.bn2.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.2.bn2.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.2.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.2.conv3.weighttorch.Size([1024, 256, 1, 1, 1]) ==>>torch.Size([1024, 256, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.2.bn3.weighttorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.2.bn3.biastorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.2.bn3.running_meantorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.2.bn3.running_vartorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.2.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.3.conv1.weighttorch.Size([256, 1024, 1, 1, 1]) ==>>torch.Size([256, 1024, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.3.bn1.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.3.bn1.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.3.bn1.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.3.bn1.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.3.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.3.conv2.weighttorch.Size([256, 256, 1, 3, 3]) ==>>torch.Size([256, 256, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer3.3.bn2.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.3.bn2.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.3.bn2.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.3.bn2.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.3.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.3.conv3.weighttorch.Size([1024, 256, 1, 1, 1]) ==>>torch.Size([1024, 256, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.3.bn3.weighttorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.3.bn3.biastorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.3.bn3.running_meantorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.3.bn3.running_vartorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.3.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.4.conv1.weighttorch.Size([256, 1024, 3, 1, 1]) ==>>torch.Size([256, 1024, 3, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.4.bn1.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.4.bn1.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.4.bn1.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.4.bn1.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.4.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.4.conv2.weighttorch.Size([256, 256, 1, 3, 3]) ==>>torch.Size([256, 256, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer3.4.bn2.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.4.bn2.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.4.bn2.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.4.bn2.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.4.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.4.conv3.weighttorch.Size([1024, 256, 1, 1, 1]) ==>>torch.Size([1024, 256, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.4.bn3.weighttorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.4.bn3.biastorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.4.bn3.running_meantorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.4.bn3.running_vartorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.4.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.5.conv1.weighttorch.Size([256, 1024, 1, 1, 1]) ==>>torch.Size([256, 1024, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.5.bn1.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.5.bn1.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.5.bn1.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.5.bn1.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.5.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.5.conv2.weighttorch.Size([256, 256, 1, 3, 3]) ==>>torch.Size([256, 256, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer3.5.bn2.weighttorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.5.bn2.biastorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.5.bn2.running_meantorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.5.bn2.running_vartorch.Size([256]) ==>>torch.Size([256])
[INFO: resnetFPN.py:  317]: layer3.5.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer3.5.conv3.weighttorch.Size([1024, 256, 1, 1, 1]) ==>>torch.Size([1024, 256, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer3.5.bn3.weighttorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.5.bn3.biastorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.5.bn3.running_meantorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.5.bn3.running_vartorch.Size([1024]) ==>>torch.Size([1024])
[INFO: resnetFPN.py:  317]: layer3.5.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer4.0.conv1.weighttorch.Size([512, 1024, 3, 1, 1]) ==>>torch.Size([512, 1024, 3, 1, 1])
[INFO: resnetFPN.py:  317]: layer4.0.bn1.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.0.bn1.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.0.bn1.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.0.bn1.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.0.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer4.0.conv2.weighttorch.Size([512, 512, 1, 3, 3]) ==>>torch.Size([512, 512, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer4.0.bn2.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.0.bn2.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.0.bn2.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.0.bn2.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.0.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer4.0.conv3.weighttorch.Size([2048, 512, 1, 1, 1]) ==>>torch.Size([2048, 512, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer4.0.bn3.weighttorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.0.bn3.biastorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.0.bn3.running_meantorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.0.bn3.running_vartorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.0.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer4.0.downsample.0.weighttorch.Size([2048, 1024, 1, 1, 1]) ==>>torch.Size([2048, 1024, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer4.0.downsample.1.weighttorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.0.downsample.1.biastorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.0.downsample.1.running_meantorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.0.downsample.1.running_vartorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.0.downsample.1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer4.1.conv1.weighttorch.Size([512, 2048, 3, 1, 1]) ==>>torch.Size([512, 2048, 3, 1, 1])
[INFO: resnetFPN.py:  317]: layer4.1.bn1.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.1.bn1.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.1.bn1.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.1.bn1.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.1.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer4.1.conv2.weighttorch.Size([512, 512, 1, 3, 3]) ==>>torch.Size([512, 512, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer4.1.bn2.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.1.bn2.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.1.bn2.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.1.bn2.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.1.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer4.1.conv3.weighttorch.Size([2048, 512, 1, 1, 1]) ==>>torch.Size([2048, 512, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer4.1.bn3.weighttorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.1.bn3.biastorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.1.bn3.running_meantorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.1.bn3.running_vartorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.1.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer4.2.conv1.weighttorch.Size([512, 2048, 1, 1, 1]) ==>>torch.Size([512, 2048, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer4.2.bn1.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.2.bn1.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.2.bn1.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.2.bn1.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.2.bn1.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer4.2.conv2.weighttorch.Size([512, 512, 1, 3, 3]) ==>>torch.Size([512, 512, 1, 3, 3])
[INFO: resnetFPN.py:  317]: layer4.2.bn2.weighttorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.2.bn2.biastorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.2.bn2.running_meantorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.2.bn2.running_vartorch.Size([512]) ==>>torch.Size([512])
[INFO: resnetFPN.py:  317]: layer4.2.bn2.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  317]: layer4.2.conv3.weighttorch.Size([2048, 512, 1, 1, 1]) ==>>torch.Size([2048, 512, 1, 1, 1])
[INFO: resnetFPN.py:  317]: layer4.2.bn3.weighttorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.2.bn3.biastorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.2.bn3.running_meantorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.2.bn3.running_vartorch.Size([2048]) ==>>torch.Size([2048])
[INFO: resnetFPN.py:  317]: layer4.2.bn3.num_batches_trackedtorch.Size([]) ==>>torch.Size([])
[INFO: resnetFPN.py:  319]: NAME IS NOT INPUT STATE DICT::>conv6.weight
[INFO: resnetFPN.py:  319]: NAME IS NOT INPUT STATE DICT::>conv7.weight
[INFO: resnetFPN.py:  319]: NAME IS NOT INPUT STATE DICT::>ego_lateral.weight
[INFO: resnetFPN.py:  319]: NAME IS NOT INPUT STATE DICT::>lateral_layer1.weight
[INFO: resnetFPN.py:  319]: NAME IS NOT INPUT STATE DICT::>lateral_layer2.weight
[INFO: resnetFPN.py:  319]: NAME IS NOT INPUT STATE DICT::>lateral_layer3.weight
[INFO: resnetFPN.py:  319]: NAME IS NOT INPUT STATE DICT::>corr_layer1.weight
[INFO: resnetFPN.py:  319]: NAME IS NOT INPUT STATE DICT::>corr_layer2.weight
[INFO: resnetFPN.py:  319]: NAME IS NOT INPUT STATE DICT::>corr_layer3.weight
[INFO: main.py:  283]: 
Lets do dataparallel

[INFO: main.py:  287]: ANCHOR_TYPE: RETINA
[INFO: main.py:  287]: ARCH: resnet50
[INFO: main.py:  287]: BATCH_SIZE: 4
[INFO: main.py:  287]: CCN_CENTRALITY: katz
[INFO: main.py:  287]: CCN_CONSTRAINTS: 
[INFO: main.py:  287]: CCN_NUM_CLASSES: 41
[INFO: main.py:  287]: CLASSWISE_NMS: False
[INFO: main.py:  287]: CLS_HEAD_TIME_SIZE: 3
[INFO: main.py:  287]: COMPUTE_PATHS: False
[INFO: main.py:  287]: COMPUTE_TUBES: False
[INFO: main.py:  287]: CONF_THRESH: 0.025
[INFO: main.py:  287]: DATASET: road
[INFO: main.py:  287]: DATA_ROOT: /jmain02/home/J2AD009/ttl04/aat50-ttl04/road-dataset/
[INFO: main.py:  287]: EVAL_EPOCHS: [30]
[INFO: main.py:  287]: FBN: True
[INFO: main.py:  287]: FREEZE_UPTO: 1
[INFO: main.py:  287]: GAMMA: 0.1
[INFO: main.py:  287]: GEN_CONF_THRESH: 0.025
[INFO: main.py:  287]: GEN_NMS: 0.5
[INFO: main.py:  287]: GEN_TOPK: 100
[INFO: main.py:  287]: HEAD_LAYERS: 3
[INFO: main.py:  287]: IOU_THRESH: 0.5
[INFO: main.py:  287]: JOINT_4M_MARGINALS: False
[INFO: main.py:  287]: LOG_START: 10
[INFO: main.py:  287]: LOG_STEP: 10
[INFO: main.py:  287]: LR: 0.0041
[INFO: main.py:  287]: MAN_SEED: 123
[INFO: main.py:  287]: MAX_EPOCHS: 30
[INFO: main.py:  287]: MAX_SEQ_STEP: 1
[INFO: main.py:  287]: MAX_SIZE: 691
[INFO: main.py:  287]: MEANS: [0.485, 0.456, 0.406]
[INFO: main.py:  287]: MILESTONES: [20, 25]
[INFO: main.py:  287]: MIN_SEQ_STEP: 1
[INFO: main.py:  287]: MIN_SIZE: 512
[INFO: main.py:  287]: MODE: train
[INFO: main.py:  287]: MODEL_PATH: /jmain02/home/J2AD009/ttl04/aat50-ttl04/3D-RetinaNet/kinetics-pt/resnet50I3D.pth
[INFO: main.py:  287]: MODEL_TYPE: I3D
[INFO: main.py:  287]: MOMENTUM: 0.9
[INFO: main.py:  287]: MULTI_GPUS: True
[INFO: main.py:  287]: NEGTIVE_THRESHOLD: 0.4
[INFO: main.py:  287]: NMS_THRESH: 0.5
[INFO: main.py:  287]: NUM_FEATURE_MAPS: 5
[INFO: main.py:  287]: NUM_WORKERS: 2
[INFO: main.py:  287]: OPTIM: SGD
[INFO: main.py:  287]: PATHS_COST_TYPE: score
[INFO: main.py:  287]: PATHS_IOUTH: 0.5
[INFO: main.py:  287]: PATHS_JUMP_GAP: 4
[INFO: main.py:  287]: PATHS_MINSCORE: 0.1
[INFO: main.py:  287]: PATHS_MIN_LEN: 6
[INFO: main.py:  287]: POSTIVE_THRESHOLD: 0.5
[INFO: main.py:  287]: REG_HEAD_TIME_SIZE: 3
[INFO: main.py:  287]: RESUME: 0
[INFO: main.py:  287]: SAVE_ROOT: /jmain02/home/J2AD009/ttl04/aat50-ttl04/road-dataset/road/cache/resnet50I3D512-Pkinetics-b4s8x1x1-roadt1-h3x3x3/
[INFO: main.py:  287]: SEQ_LEN: 8
[INFO: main.py:  287]: STDS: [0.229, 0.224, 0.225]
[INFO: main.py:  287]: SUBSETS: ['val_1']
[INFO: main.py:  287]: TENSORBOARD: 1
[INFO: main.py:  287]: TEST_BATCH_SIZE: 1
[INFO: main.py:  287]: TEST_SEQ_LEN: 8
[INFO: main.py:  287]: TEST_SUBSETS: ['val_1']
[INFO: main.py:  287]: TOPK: 10
[INFO: main.py:  287]: TRAIN_SUBSETS: ['train_1']
[INFO: main.py:  287]: TRIM_METHOD: none
[INFO: main.py:  287]: TUBES_ALPHA: 0
[INFO: main.py:  287]: TUBES_EVAL_THRESHS: [0.2, 0.5]
[INFO: main.py:  287]: TUBES_MINLEN: 5
[INFO: main.py:  287]: TUBES_TOPK: 10
[INFO: main.py:  287]: VAL_STEP: 2
[INFO: main.py:  287]: VAL_SUBSETS: ['val_1']
[INFO: main.py:  287]: WEIGHT_DECAY: 0.0001
[INFO: main.py:  287]: all_classes: [['agent_ness'], ['Ped', 'Car', 'Cyc', 'Mobike', 'MedVeh', 'LarVeh', 'Bus', 'EmVeh', 'TL', 'OthTL'], ['Red', 'Amber', 'Green', 'MovAway', 'MovTow', 'Mov', 'Brake', 'Stop', 'IncatLft', 'IncatRht', 'HazLit', 'TurLft', 'TurRht', 'Ovtak', 'Wait2X', 'XingFmLft', 'XingFmRht', 'Xing', 'PushObj'], ['VehLane', 'OutgoLane', 'OutgoCycLane', 'IncomLane', 'IncomCycLane', 'Pav', 'LftPav', 'RhtPav', 'Jun', 'xing', 'BusStop', 'parking'], ['Bus-MovAway', 'Bus-MovTow', 'Bus-Stop', 'Bus-XingFmLft', 'Car-Brake', 'Car-IncatLft', 'Car-IncatRht', 'Car-MovAway', 'Car-MovTow', 'Car-Stop', 'Car-TurLft', 'Car-TurRht', 'Car-XingFmLft', 'Car-XingFmRht', 'Cyc-MovAway', 'Cyc-MovTow', 'Cyc-Stop', 'Cyc-TurLft', 'Cyc-XingFmLft', 'Cyc-XingFmRht', 'LarVeh-Stop', 'MedVeh-IncatLft', 'MedVeh-MovTow', 'MedVeh-Stop', 'MedVeh-TurRht', 'OthTL-Green', 'OthTL-Red', 'Ped-Mov', 'Ped-MovAway', 'Ped-MovTow', 'Ped-PushObj', 'Ped-Stop', 'Ped-Wait2X', 'Ped-Xing', 'Ped-XingFmLft', 'Ped-XingFmRht', 'TL-Amber', 'TL-Green', 'TL-Red'], ['Bus-MovTow-IncomLane', 'Bus-MovTow-Jun', 'Bus-Stop-IncomLane', 'Bus-Stop-VehLane', 'Bus-XingFmLft-Jun', 'Car-Brake-Jun', 'Car-Brake-VehLane', 'Car-IncatLft-Jun', 'Car-IncatLft-VehLane', 'Car-IncatRht-IncomLane', 'Car-IncatRht-Jun', 'Car-MovAway-Jun', 'Car-MovAway-OutgoLane', 'Car-MovAway-VehLane', 'Car-MovTow-IncomLane', 'Car-MovTow-Jun', 'Car-Stop-IncomLane', 'Car-Stop-Jun', 'Car-Stop-VehLane', 'Car-TurLft-Jun', 'Car-TurLft-VehLane', 'Car-TurRht-IncomLane', 'Car-TurRht-Jun', 'Car-XingFmLft-Jun', 'Cyc-MovAway-Jun', 'Cyc-MovAway-LftPav', 'Cyc-MovAway-OutgoCycLane', 'Cyc-MovAway-OutgoLane', 'Cyc-MovAway-VehLane', 'Cyc-MovTow-IncomCycLane', 'Cyc-MovTow-IncomLane', 'Cyc-MovTow-Jun', 'Cyc-MovTow-LftPav', 'Cyc-Stop-IncomCycLane', 'Cyc-Stop-IncomLane', 'Cyc-Stop-Jun', 'Cyc-TurLft-Jun', 'Cyc-XingFmLft-Jun', 'MedVeh-MovTow-IncomLane', 'MedVeh-MovTow-Jun', 'MedVeh-Stop-IncomLane', 'MedVeh-Stop-Jun', 'MedVeh-TurRht-Jun', 'Ped-Mov-Pav', 'Ped-MovAway-LftPav', 'Ped-MovAway-Pav', 'Ped-MovAway-RhtPav', 'Ped-MovTow-IncomLane', 'Ped-MovTow-LftPav', 'Ped-MovTow-RhtPav', 'Ped-MovTow-VehLane', 'Ped-PushObj-LftPav', 'Ped-PushObj-RhtPav', 'Ped-Stop-BusStop', 'Ped-Stop-LftPav', 'Ped-Stop-Pav', 'Ped-Stop-RhtPav', 'Ped-Stop-VehLane', 'Ped-Wait2X-LftPav', 'Ped-Wait2X-RhtPav', 'Ped-XingFmLft-IncomLane', 'Ped-XingFmLft-Jun', 'Ped-XingFmLft-VehLane', 'Ped-XingFmLft-xing', 'Ped-XingFmRht-IncomLane', 'Ped-XingFmRht-Jun', 'Ped-XingFmRht-RhtPav', 'Ped-XingFmRht-VehLane']]
[INFO: main.py:  287]: ar: 9
[INFO: main.py:  287]: ccn_num_classes: 41
[INFO: main.py:  287]: ego_classes: ['AV-Stop', 'AV-Mov', 'AV-TurRht', 'AV-TurLft', 'AV-MovRht', 'AV-MovLft', 'AV-Ovtak']
[INFO: main.py:  287]: exp_name: resnet50I3D512-Pkinetics-b4s8x1x1-roadt1-h3x3x3
[INFO: main.py:  287]: head_size: 256
[INFO: main.py:  287]: hostname: dgk507
[INFO: main.py:  287]: label_types: ['agent_ness', 'agent', 'action', 'loc', 'duplex', 'triplet']
[INFO: main.py:  287]: log_dir: logs/resnet50I3D512-Pkinetics-b4s8x1x1-roadt1-h3x3x3/
[INFO: main.py:  287]: model_3d_layers: [[0, 1, 2], [0, 2], [0, 2, 4], [0, 1]]
[INFO: main.py:  287]: model_init: kinetics
[INFO: main.py:  287]: model_perms: [3, 4, 6, 3]
[INFO: main.py:  287]: model_subtype: I3D
[INFO: main.py:  287]: non_local_inds: [[], [], [], []]
[INFO: main.py:  287]: num_classes: 149
[INFO: main.py:  287]: num_classes_list: [1, 10, 19, 12, 39, 68]
[INFO: main.py:  287]: num_ego_classes: 7
[INFO: main.py:  287]: num_label_types: 6
[INFO: main.py:  287]: user: aat50-ttl04
module.backbone.layer1.0.conv1.weight is trained at the rate of 0.0041
module.backbone.layer1.0.conv2.weight is trained at the rate of 0.0041
module.backbone.layer1.0.conv3.weight is trained at the rate of 0.0041
module.backbone.layer1.0.downsample.0.weight is trained at the rate of 0.0041
module.backbone.layer1.1.conv1.weight is trained at the rate of 0.0041
module.backbone.layer1.1.conv2.weight is trained at the rate of 0.0041
module.backbone.layer1.1.conv3.weight is trained at the rate of 0.0041
module.backbone.layer1.2.conv1.weight is trained at the rate of 0.0041
module.backbone.layer1.2.conv2.weight is trained at the rate of 0.0041
module.backbone.layer1.2.conv3.weight is trained at the rate of 0.0041
module.backbone.layer2.0.conv1.weight is trained at the rate of 0.0041
module.backbone.layer2.0.conv2.weight is trained at the rate of 0.0041
module.backbone.layer2.0.conv3.weight is trained at the rate of 0.0041
module.backbone.layer2.0.downsample.0.weight is trained at the rate of 0.0041
module.backbone.layer2.1.conv1.weight is trained at the rate of 0.0041
module.backbone.layer2.1.conv2.weight is trained at the rate of 0.0041
module.backbone.layer2.1.conv3.weight is trained at the rate of 0.0041
module.backbone.layer2.2.conv1.weight is trained at the rate of 0.0041
module.backbone.layer2.2.conv2.weight is trained at the rate of 0.0041
module.backbone.layer2.2.conv3.weight is trained at the rate of 0.0041
module.backbone.layer2.3.conv1.weight is trained at the rate of 0.0041
module.backbone.layer2.3.conv2.weight is trained at the rate of 0.0041
module.backbone.layer2.3.conv3.weight is trained at the rate of 0.0041
module.backbone.layer3.0.conv1.weight is trained at the rate of 0.0041
module.backbone.layer3.0.conv2.weight is trained at the rate of 0.0041
module.backbone.layer3.0.conv3.weight is trained at the rate of 0.0041
module.backbone.layer3.0.downsample.0.weight is trained at the rate of 0.0041
module.backbone.layer3.1.conv1.weight is trained at the rate of 0.0041
module.backbone.layer3.1.conv2.weight is trained at the rate of 0.0041
module.backbone.layer3.1.conv3.weight is trained at the rate of 0.0041
module.backbone.layer3.2.conv1.weight is trained at the rate of 0.0041
module.backbone.layer3.2.conv2.weight is trained at the rate of 0.0041
module.backbone.layer3.2.conv3.weight is trained at the rate of 0.0041
module.backbone.layer3.3.conv1.weight is trained at the rate of 0.0041
module.backbone.layer3.3.conv2.weight is trained at the rate of 0.0041
module.backbone.layer3.3.conv3.weight is trained at the rate of 0.0041
module.backbone.layer3.4.conv1.weight is trained at the rate of 0.0041
module.backbone.layer3.4.conv2.weight is trained at the rate of 0.0041
module.backbone.layer3.4.conv3.weight is trained at the rate of 0.0041
module.backbone.layer3.5.conv1.weight is trained at the rate of 0.0041
module.backbone.layer3.5.conv2.weight is trained at the rate of 0.0041
module.backbone.layer3.5.conv3.weight is trained at the rate of 0.0041
module.backbone.layer4.0.conv1.weight is trained at the rate of 0.0041
module.backbone.layer4.0.conv2.weight is trained at the rate of 0.0041
module.backbone.layer4.0.conv3.weight is trained at the rate of 0.0041
module.backbone.layer4.0.downsample.0.weight is trained at the rate of 0.0041
module.backbone.layer4.1.conv1.weight is trained at the rate of 0.0041
module.backbone.layer4.1.conv2.weight is trained at the rate of 0.0041
module.backbone.layer4.1.conv3.weight is trained at the rate of 0.0041
module.backbone.layer4.2.conv1.weight is trained at the rate of 0.0041
module.backbone.layer4.2.conv2.weight is trained at the rate of 0.0041
module.backbone.layer4.2.conv3.weight is trained at the rate of 0.0041
module.backbone.conv6.weight is trained at the rate of 0.0041
module.backbone.conv7.weight is trained at the rate of 0.0041
module.backbone.ego_lateral.weight is trained at the rate of 0.0041
module.backbone.lateral_layer1.weight is trained at the rate of 0.0041
module.backbone.lateral_layer2.weight is trained at the rate of 0.0041
module.backbone.lateral_layer3.weight is trained at the rate of 0.0041
module.backbone.corr_layer1.weight is trained at the rate of 0.0041
module.backbone.corr_layer2.weight is trained at the rate of 0.0041
module.backbone.corr_layer3.weight is trained at the rate of 0.0041
module.reg_heads.0.weight is trained at the rate of 0.0041
module.reg_heads.0.bias is trained at the rate of 0.0082
module.reg_heads.2.weight is trained at the rate of 0.0041
module.reg_heads.2.bias is trained at the rate of 0.0082
module.reg_heads.4.weight is trained at the rate of 0.0041
module.reg_heads.4.bias is trained at the rate of 0.0082
module.reg_heads.6.weight is trained at the rate of 0.0041
module.reg_heads.6.bias is trained at the rate of 0.0082
module.cls_heads.0.weight is trained at the rate of 0.0041
module.cls_heads.0.bias is trained at the rate of 0.0082
module.cls_heads.2.weight is trained at the rate of 0.0041
module.cls_heads.2.bias is trained at the rate of 0.0082
module.cls_heads.4.weight is trained at the rate of 0.0041
module.cls_heads.4.bias is trained at the rate of 0.0082
module.cls_heads.6.weight is trained at the rate of 0.0041
module.cls_heads.6.bias is trained at the rate of 0.0082
Traceback (most recent call last):
  File "/jmain02/home/J2AD009/ttl04/aat50-ttl04/anaconda3/envs/ccn/lib/python3.7/site-packages/tensorboardX/record_writer.py", line 47, in directory_check
    factory = REGISTERED_FACTORIES[prefix]
KeyError: 'logs/resnet50I3D512-Pkinetics-b4s8x1x1-roadt1-h3x3x3//tboard-train-03-02-15x'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 309, in <module>
    main()
  File "main.py", line 295, in main
    train(args, net, train_dataset, val_dataset)
  File "/jmain02/home/J2AD009/ttl04/aat50-ttl04/3D-RetinaNet/train.py", line 42, in train
    args.sw = SummaryWriter(log_dir)
  File "/jmain02/home/J2AD009/ttl04/aat50-ttl04/anaconda3/envs/ccn/lib/python3.7/site-packages/tensorboardX/writer.py", line 301, in __init__
    self._get_file_writer()
  File "/jmain02/home/J2AD009/ttl04/aat50-ttl04/anaconda3/envs/ccn/lib/python3.7/site-packages/tensorboardX/writer.py", line 353, in _get_file_writer
    **self.kwargs)
  File "/jmain02/home/J2AD009/ttl04/aat50-ttl04/anaconda3/envs/ccn/lib/python3.7/site-packages/tensorboardX/writer.py", line 106, in __init__
    logdir, max_queue, flush_secs, filename_suffix)
  File "/jmain02/home/J2AD009/ttl04/aat50-ttl04/anaconda3/envs/ccn/lib/python3.7/site-packages/tensorboardX/event_file_writer.py", line 104, in __init__
    directory_check(self._logdir)
  File "/jmain02/home/J2AD009/ttl04/aat50-ttl04/anaconda3/envs/ccn/lib/python3.7/site-packages/tensorboardX/record_writer.py", line 51, in directory_check
    os.makedirs(path)
  File "/jmain02/home/J2AD009/ttl04/aat50-ttl04/anaconda3/envs/ccn/lib/python3.7/os.py", line 223, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: 'logs/resnet50I3D512-Pkinetics-b4s8x1x1-roadt1-h3x3x3//tboard-train-03-02-15x'
